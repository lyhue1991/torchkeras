
# Pytorchâ¤ï¸Keras

English | [ç®€ä½“ä¸­æ–‡](README.md)


The torchkeras library is a simple tool for training neural network in pytorch jusk in a keras style. ğŸ˜‹ğŸ˜‹


## 1, Introduction


With torchkeras, You need not to write your training loop with many lines of code, all you need to do is just 

like these two steps as below:

(i) create your network and wrap it and the loss_fn together with torchkeras.KerasModel like this: 
`model = torchkeras.KerasModel(net,loss_fn=nn.BCEWithLogitsLoss())`.

(ii) fit your model with the training data and validate data.


The main code of use torchkeras is like below.

```python
import torch 
import torchkeras

#use torchkeras.KerasModel 
model = torchkeras.KerasModel(net,
                              loss_fn = nn.BCEWithLogitsLoss(),
                              optimizer= torch.optim.Adam(net.parameters(),lr = 0.001),
                              metrics_dict = {"acc":torchmetrics.Accuracy(task='binary')}
                             )
dfhistory=model.fit(train_data=dl_train, 
                    val_data=dl_val, 
                    epochs=20, 
                    patience=3, 
                    ckpt_path='checkpoint.pt',
                    monitor="val_acc",
                    mode="max",
                    plot=True
                   )

```

![](./data/torchkeras_plot.gif)



**This project seems somehow powerful, but the source code is very simple.**

**Actually, only about 200 lines of Python code.**

**If you want to understand or modify some details of this project, feel free to read and change the source code!!!**

```python

```

## 2, Features 


The main features supported by torchkeras are listed below.

Versions when these features are introduced and the libraries which they used  or inspired from are given.



|features| supported from version | used or inspired by library  |
|:----|:-------------------:|:--------------|
|âœ… training progress bar | 3.0.0   | use tqdm,inspired by keras|
|âœ… training metrics  | 3.0.0   | inspired by pytorch_lightning |
|âœ… notebook visualization in traning |  3.8.0  |inspired by fastai |
|âœ… early stopping | 3.0.0   | inspired by keras |
|âœ… gpu training | 3.0.0    |use accelerate|
|âœ… multi-gpus training(ddp) |   3.6.0 | use accelerate|
|âœ… fp16/bf16 training|   3.6.0  | use accelerate|
|âœ… tensorboard callback |   3.7.0  |use tensorboard |
|âœ… wandb callback |  3.7.0 |use wandb |


```python

```

### 3, Basic Examples 

You can follow these full examples to get started with torchkeras.


|example| read notebook code     |  run example in kaggle| 
|:----|:-------------------------|:-----------:|
|â‘ kerasmodel basic ğŸ”¥ğŸ”¥|  [**torchkeras.KerasModel example**](./01ï¼Œkerasmodel_example.ipynb)  |  <br><div></a><a href="https://www.kaggle.com/lyhue1991/kerasmodel-example"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a></div><br>  |
|â‘¡kerasmodel wandb ğŸ”¥ğŸ”¥ğŸ”¥|[**torchkeras.KerasModel with wandb demo**](./02ï¼Œkerasmodel_wandb_demo.ipynb)   |  <br><div></a><a href="https://www.kaggle.com/lyhue1991/kerasmodel-wandb-example"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a></div><br>  |
|â‘¢kerasmodel tunning ğŸ”¥ğŸ”¥ğŸ”¥|[**torchkeras.KerasModel with wandb sweep demo**](./03ï¼Œkerasmodel_tuning_demo.ipynb)   |  <br><div></a><a href="https://www.kaggle.com/lyhue1991/torchkeras-loves-wandb-sweep"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a></div><br>  |
|â‘£kerasmodel tensorboard | [**torchkeras.KerasModel with tensorboard example**](./04ï¼Œkerasmodel_tensorboard_demo.ipynb)   |  |
|â‘¤kerasmodel ddp/tpu | [**torchkeras.KerasModel  ddp tpu examples**](https://www.kaggle.com/code/lyhue1991/torchkeras-ddp-tpu-examples)   |<br><div></a><a href="https://www.kaggle.com/lyhue1991/torchkeras-ddp-tpu-examples"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a></div><br>  |



### 4, Advanced Examples 

In some using cases, because of the differences  of the model input types, you need to rewrite the StepRunner of 
KerasModel. Here are some examples.

|example|model library  |notebook |
|:----|:-----------|:-----------:|
||||
|**RL**|||
|ReinforcementLearningâ€”â€”Q-LearningğŸ”¥ğŸ”¥|- |[Q-learning](./examples/Q-learning.ipynb)|
|ReinforcementLearningâ€”â€”DQN|- |[DQN](./examples/DQN.ipynb)|
||||
|**CV**|||
|ImageClassificationâ€”â€”Resnet|  -  | [Resnet](./examples/ResNet.ipynb) |
|ImageSegmentationâ€”â€”UNet|  - | [UNet](./examples/UNet.ipynb) |
|ObjectDetectionâ€”â€”SSD| -  | [SSD](./examples/SSD.ipynb) |
|OCRâ€”â€”CRNN ğŸ”¥ğŸ”¥| -  | [CRNN-CTC](./examples/CRNN_CTC.ipynb) |
|ImageClassificationâ€”â€”SwinTransformer|timm| [Swin](./examples/SwinTransformerâ€”â€”timm.ipynb)|
|ObjectDetectionâ€”â€”FasterRCNN| torchvision  |  [FasterRCNN](./examples/FasterRCNNâ€”â€”vision.ipynb) | 
|ImageSegmentationâ€”â€”DeepLabV3++ | segmentation_models_pytorch |  [Deeplabv3++](./examples/Deeplabv3plusâ€”â€”smp.ipynb) |
|InstanceSegmentationâ€”â€”MaskRCNN | detectron2 |  [MaskRCNN](./examples/MaskRCNNâ€”â€”detectron2.ipynb) |
|ObjectDetectionâ€”â€”YOLOv8 ğŸ”¥ğŸ”¥ğŸ”¥| ultralytics |  [YOLOv8](./examples/YOLOV8_Detectâ€”â€”ultralytics.ipynb) |
|InstanceSegmentationâ€”â€”YOLOv8 ğŸ”¥ğŸ”¥ğŸ”¥| ultralytics |  [YOLOv8](./examples/YOLOV8_Segmentâ€”â€”ultralytics.ipynb) |
||||
|**NLP**|||
|Seq2Seqâ€”â€”TransformerğŸ”¥ğŸ”¥| - |  [Transformer](./examples/Dive_into_Transformer.ipynb) |
|TextGenerationâ€”â€”LlamağŸ”¥| - |  [Llama](./examples/Dive_into_Llama.ipynb) |
|TextClassificationâ€”â€”BERT | transformers |  [BERT](./examples/BERTâ€”â€”transformers.ipynb) |
|TokenClassificationâ€”â€”BERT | transformers |  [BERT_NER](./examples/BERT_NERâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”ChatGLM2_LoRA ğŸ”¥ğŸ”¥ğŸ”¥| transformers,peft |  [ChatGLM2_LoRA](./examples/ChatGLM2_LoRAâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”ChatGLM2_AdaLoRA ğŸ”¥| transformers,peft |  [ChatGLM2_AdaLoRA](./examples/ChatGLM2_AdaLoRAâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”ChatGLM2_QLoRAğŸ”¥ | transformers |  [ChatGLM2_QLoRA_Kaggle](./examples/ChatGLM2_QLoRA_Kaggleâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”BaiChuan13B_QLoRAğŸ”¥ | transformers |  [BaiChuan13B_QLoRA](./examples/BaiChuan13B_QLoRAâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”BaiChuan13B_NER ğŸ”¥ğŸ”¥ğŸ”¥| transformers |  [BaiChuan13B_NER](./examples/BaiChuan13B_NERâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”BaiChuan13B_MultiRounds ğŸ”¥| transformers |  [BaiChuan13B_MultiRounds](./examples/BaiChuan13B_MultiRoundsâ€”â€”transformers.ipynb) |
|FinetuneLLMâ€”â€”Qwen7B_MultiRounds ğŸ”¥ğŸ”¥ğŸ”¥| transformers |  [Qwen7B_MultiRounds](./examples/Qwen7B_MultiRoundsâ€”â€”transformers.ipynb) |


**If you want to understand or modify some details of this project, feel free to read and change the source code!!!**

Any other questions, you can contact the author form the wechat official account below:

**ç®—æ³•ç¾é£Ÿå±‹** 


![](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)

